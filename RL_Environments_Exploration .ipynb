{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5046afdb",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Environments Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953ffb1",
   "metadata": {},
   "source": [
    "## 1. Print the Total Number of Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b307b814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of environments: 44\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Retrieve all registered environments\n",
    "envs = gym.envs.registry.keys()\n",
    "\n",
    "# Count the total number of environments\n",
    "total_envs = len(envs)\n",
    "print(f\"Total number of environments: {total_envs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacb88c",
   "metadata": {},
   "source": [
    "## 2. Print All Registered Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve all registered environments\n",
    "envs = gym.envs.registry.all()\n",
    "\n",
    "# Print the names of all environments\n",
    "env_names = sorted([env_spec.id for env_spec in envs])\n",
    "for name in env_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b9591",
   "metadata": {},
   "source": [
    "## 3. Explore Different Environments in RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3adec",
   "metadata": {},
   "source": [
    "\n",
    "We will explore some classic Gym environments and describe their MDP components:\n",
    "- **CartPole**\n",
    "- **FrozenLake**\n",
    "- **MountainCar**\n",
    "- **Blackjack**\n",
    "- **Taxi**\n",
    "- **CliffWalking**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12cca3",
   "metadata": {},
   "source": [
    "### CartPole Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345f2708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(2)\n",
      "Observation Space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "\n",
      "MDP Definition for CartPole:\n",
      "States: Continuous observation of [cart position, cart velocity, pole angle, pole angular velocity]\n",
      "Actions: {0: Push cart left, 1: Push cart right}\n",
      "Transition: Deterministic physics-based transition depending on force and pole dynamics\n",
      "Reward: +1 for every timestep the pole remains upright\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "\n",
    "print(\"\\nMDP Definition for CartPole:\")\n",
    "print(\"States: Continuous observation of [cart position, cart velocity, pole angle, pole angular velocity]\")\n",
    "print(\"Actions: {0: Push cart left, 1: Push cart right}\")\n",
    "print(\"Transition: Deterministic physics-based transition depending on force and pole dynamics\")\n",
    "print(\"Reward: +1 for every timestep the pole remains upright\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69331f",
   "metadata": {},
   "source": [
    "### FrozenLake Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a92f3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(4)\n",
      "Observation Space: Discrete(16)\n",
      "\n",
      "MDP Definition for FrozenLake:\n",
      "States: Discrete cells in a grid (S, F, H, G)\n",
      "Actions: {0: Left, 1: Down, 2: Right, 3: Up}\n",
      "Transition: Stochastic (due to slipperiness)\n",
      "Reward: +1 for reaching the goal (G), 0 otherwise, - penalty for falling into hole (H)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make(\"FrozenLake-v1\", is_slippery=True)\n",
    "\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "\n",
    "print(\"\\nMDP Definition for FrozenLake:\")\n",
    "print(\"States: Discrete cells in a grid (S, F, H, G)\")\n",
    "print(\"Actions: {0: Left, 1: Down, 2: Right, 3: Up}\")\n",
    "print(\"Transition: Stochastic (due to slipperiness)\")\n",
    "print(\"Reward: +1 for reaching the goal (G), 0 otherwise, - penalty for falling into hole (H)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a31968",
   "metadata": {},
   "source": [
    "### MountainCar Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2587a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(3)\n",
      "Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "\n",
      "MDP Definition for MountainCar:\n",
      "States: Continuous observation of [position, velocity]\n",
      "Actions: {0: Push left, 1: No push, 2: Push right}\n",
      "Transition: Deterministic physics-based motion\n",
      "Reward: -1 per timestep until the goal is reached at the top of the hill\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "\n",
    "print(\"\\nMDP Definition for MountainCar:\")\n",
    "print(\"States: Continuous observation of [position, velocity]\")\n",
    "print(\"Actions: {0: Push left, 1: No push, 2: Push right}\")\n",
    "print(\"Transition: Deterministic physics-based motion\")\n",
    "print(\"Reward: -1 per timestep until the goal is reached at the top of the hill\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18011f2c",
   "metadata": {},
   "source": [
    "### Blackjack Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2de685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(2)\n",
      "Observation Space: Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
      "\n",
      "MDP Definition for Blackjack:\n",
      "States: Tuple (player_sum, dealer_card, usable_ace)\n",
      "Actions: {0: Stick, 1: Hit}\n",
      "Transition: Stochastic, depends on card draw\n",
      "Reward: +1 win, 0 draw, -1 lose\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "\n",
    "print(\"\\nMDP Definition for Blackjack:\")\n",
    "print(\"States: Tuple (player_sum, dealer_card, usable_ace)\")\n",
    "print(\"Actions: {0: Stick, 1: Hit}\")\n",
    "print(\"Transition: Stochastic, depends on card draw\")\n",
    "print(\"Reward: +1 win, 0 draw, -1 lose\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0e3dd",
   "metadata": {},
   "source": [
    "### Taxi Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f49f67ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(6)\n",
      "Observation Space: Discrete(500)\n",
      "\n",
      "MDP Definition for Taxi:\n",
      "States: Discrete (taxi position, passenger location, destination)\n",
      "Actions: {0: South, 1: North, 2: East, 3: West, 4: Pickup, 5: Dropoff}\n",
      "Transition: Deterministic based on grid movement and passenger interactions\n",
      "Reward: -1 per timestep, +20 successful dropoff, -10 illegal pickup/dropoff\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "\n",
    "print(\"\\nMDP Definition for Taxi:\")\n",
    "print(\"States: Discrete (taxi position, passenger location, destination)\")\n",
    "print(\"Actions: {0: South, 1: North, 2: East, 3: West, 4: Pickup, 5: Dropoff}\")\n",
    "print(\"Transition: Deterministic based on grid movement and passenger interactions\")\n",
    "print(\"Reward: -1 per timestep, +20 successful dropoff, -10 illegal pickup/dropoff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11285a8",
   "metadata": {},
   "source": [
    "### CliffWalking Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b248bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(4)\n",
      "Observation Space: Discrete(48)\n",
      "\n",
      "MDP Definition for CliffWalking:\n",
      "States: Discrete grid states (start, goal, cliff cells)\n",
      "Actions: {0: Up, 1: Right, 2: Down, 3: Left}\n",
      "Transition: Deterministic moves\n",
      "Reward: -1 per step, -100 if agent falls into the cliff, 0 at the goal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make(\"CliffWalking-v0\")\n",
    "\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "\n",
    "print(\"\\nMDP Definition for CliffWalking:\")\n",
    "print(\"States: Discrete grid states (start, goal, cliff cells)\")\n",
    "print(\"Actions: {0: Up, 1: Right, 2: Down, 3: Left}\")\n",
    "print(\"Transition: Deterministic moves\")\n",
    "print(\"Reward: -1 per step, -100 if agent falls into the cliff, 0 at the goal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356cc1d-fa24-4e56-afb0-29b0fec1a770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0fa08-0394-4c37-bc9e-8bd1797f25fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
