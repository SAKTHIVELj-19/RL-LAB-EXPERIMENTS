{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb36699-c2de-4c7b-b4ba-804a57d07753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3491c306-a581-4560-b499-c015e3dc425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Define Environment for Task 1\n",
    "class SimpleEnv:\n",
    "    def __init__(self):\n",
    "        self.start_state = 0\n",
    "        self.goal_state = 5\n",
    "        self.state = self.start_state\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.start_state\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Action: +1 or -1\n",
    "        Reward: +10 if reach goal, else 0\n",
    "        \"\"\"\n",
    "        self.state += action\n",
    "        self.state = max(0, min(self.state, self.goal_state))  # keep in [0,5]\n",
    "\n",
    "        if self.state == self.goal_state:\n",
    "            return self.state, 10, True\n",
    "        else:\n",
    "            return self.state, 0, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e96e4c8-3b49-4695-a4c3-14c3a1e16f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Define Random Agent (Task 1)\n",
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        self.actions = [-1, +1]\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        return random.choice(self.actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc56b3d5-8477-456b-b08c-79c325f504ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Trajectory: [0, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 1, 2, 3, 2, 3, 4, 5]\n",
      "Task 1 - Total Reward: 10\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Run a single episode for Task 1\n",
    "env1 = SimpleEnv()\n",
    "agent1 = RandomAgent()\n",
    "\n",
    "state = env1.reset()\n",
    "done = False\n",
    "trajectory = [state]\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent1.choose_action(state)\n",
    "    next_state, reward, done = env1.step(action)\n",
    "    total_reward += reward\n",
    "    trajectory.append(next_state)\n",
    "    state = next_state\n",
    "\n",
    "print(\"Task 1 - Trajectory:\", trajectory)\n",
    "print(\"Task 1 - Total Reward:\", total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380d4805-7caa-4afb-9429-6b50bc1f3ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode...\n",
      "Step 0: State=0, Action=1, Next State=1, Reward=0\n",
      "Step 1: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 2: State=2, Action=-1, Next State=1, Reward=0\n",
      "Step 3: State=1, Action=-1, Next State=0, Reward=0\n",
      "Step 4: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 5: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 6: State=0, Action=1, Next State=1, Reward=0\n",
      "Step 7: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 8: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 9: State=3, Action=1, Next State=4, Reward=0\n",
      "Step 10: State=4, Action=1, Next State=5, Reward=10\n",
      "Task 1 - Total Reward: 10\n"
     ]
    }
   ],
   "source": [
    "# Run a single episode for Task 1 with step-by-step log\n",
    "env1 = SimpleEnv()\n",
    "agent1 = RandomAgent()\n",
    "\n",
    "state = env1.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "step = 0\n",
    "\n",
    "print(\"Starting episode...\")\n",
    "\n",
    "while not done:\n",
    "    action = agent1.choose_action(state)\n",
    "    next_state, reward, done = env1.step(action)\n",
    "    print(f\"Step {step}: State={state}, Action={action}, Next State={next_state}, Reward={reward}\")\n",
    "    \n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    step += 1\n",
    "\n",
    "print(\"Task 1 - Total Reward:\", total_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a988df-c535-481e-bd3a-c6d432a4ea7f",
   "metadata": {},
   "source": [
    "TASK-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e83fd074-91a1-411b-8ee5-892b47c95503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode...\n",
      "Step 0: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 1: State=0, Action=1, Next State=1, Reward=0\n",
      "Step 2: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 3: State=2, Action=-1, Next State=1, Reward=0\n",
      "Step 4: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 5: State=2, Action=-1, Next State=1, Reward=0\n",
      "Step 6: State=1, Action=-1, Next State=0, Reward=0\n",
      "Step 7: State=0, Action=1, Next State=1, Reward=0\n",
      "Step 8: State=1, Action=-1, Next State=0, Reward=0\n",
      "Step 9: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 10: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 11: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 12: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 13: State=0, Action=-1, Next State=0, Reward=0\n",
      "Step 14: State=0, Action=1, Next State=1, Reward=0\n",
      "Step 15: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 16: State=2, Action=-1, Next State=1, Reward=0\n",
      "Step 17: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 18: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 19: State=3, Action=-1, Next State=2, Reward=0\n",
      "Step 20: State=2, Action=-1, Next State=1, Reward=0\n",
      "Step 21: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 22: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 23: State=3, Action=1, Next State=4, Reward=0\n",
      "Step 24: State=4, Action=1, Next State=5, Reward=-5\n",
      "Step 25: State=5, Action=-1, Next State=4, Reward=0\n",
      "Step 26: State=4, Action=-1, Next State=3, Reward=0\n",
      "Step 27: State=3, Action=-1, Next State=2, Reward=0\n",
      "Step 28: State=2, Action=-1, Next State=1, Reward=0\n",
      "Step 29: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 30: State=2, Action=-1, Next State=1, Reward=0\n",
      "Step 31: State=1, Action=-1, Next State=0, Reward=0\n",
      "Step 32: State=0, Action=1, Next State=1, Reward=0\n",
      "Step 33: State=1, Action=1, Next State=2, Reward=0\n",
      "Step 34: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 35: State=3, Action=1, Next State=4, Reward=0\n",
      "Step 36: State=4, Action=-1, Next State=3, Reward=0\n",
      "Step 37: State=3, Action=-1, Next State=2, Reward=0\n",
      "Step 38: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 39: State=3, Action=-1, Next State=2, Reward=0\n",
      "Step 40: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 41: State=3, Action=-1, Next State=2, Reward=0\n",
      "Step 42: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 43: State=3, Action=-1, Next State=2, Reward=0\n",
      "Step 44: State=2, Action=1, Next State=3, Reward=0\n",
      "Step 45: State=3, Action=1, Next State=4, Reward=0\n",
      "Step 46: State=4, Action=-1, Next State=3, Reward=0\n",
      "Step 47: State=3, Action=1, Next State=4, Reward=0\n",
      "Step 48: State=4, Action=1, Next State=5, Reward=-5\n",
      "Step 49: State=5, Action=-1, Next State=4, Reward=0\n",
      "Step 50: State=4, Action=1, Next State=5, Reward=-5\n",
      "Step 51: State=5, Action=1, Next State=6, Reward=0\n",
      "Step 52: State=6, Action=-1, Next State=5, Reward=-5\n",
      "Step 53: State=5, Action=-1, Next State=4, Reward=0\n",
      "Step 54: State=4, Action=-1, Next State=3, Reward=0\n",
      "Step 55: State=3, Action=1, Next State=4, Reward=0\n",
      "Step 56: State=4, Action=1, Next State=5, Reward=-5\n",
      "Step 57: State=5, Action=1, Next State=6, Reward=0\n",
      "Step 58: State=6, Action=1, Next State=7, Reward=0\n",
      "Step 59: State=7, Action=-1, Next State=6, Reward=0\n",
      "Step 60: State=6, Action=-1, Next State=5, Reward=-5\n",
      "Step 61: State=5, Action=-1, Next State=4, Reward=0\n",
      "Step 62: State=4, Action=1, Next State=5, Reward=-5\n",
      "Step 63: State=5, Action=1, Next State=6, Reward=0\n",
      "Step 64: State=6, Action=1, Next State=7, Reward=0\n",
      "Step 65: State=7, Action=-1, Next State=6, Reward=0\n",
      "Step 66: State=6, Action=-1, Next State=5, Reward=-5\n",
      "Step 67: State=5, Action=-1, Next State=4, Reward=0\n",
      "Step 68: State=4, Action=1, Next State=5, Reward=-5\n",
      "Step 69: State=5, Action=1, Next State=6, Reward=0\n",
      "Step 70: State=6, Action=-1, Next State=5, Reward=-5\n",
      "Step 71: State=5, Action=1, Next State=6, Reward=0\n",
      "Step 72: State=6, Action=1, Next State=7, Reward=0\n",
      "Step 73: State=7, Action=1, Next State=8, Reward=0\n",
      "Step 74: State=8, Action=1, Next State=9, Reward=0\n",
      "Step 75: State=9, Action=-1, Next State=8, Reward=0\n",
      "Step 76: State=8, Action=1, Next State=9, Reward=0\n",
      "Step 77: State=9, Action=1, Next State=10, Reward=20\n",
      "Task 2 - Total Reward: -30\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Environment\n",
    "class TreasureHuntEnv:\n",
    "    def __init__(self):\n",
    "        self.start_state = 0\n",
    "        self.goal_state = 10\n",
    "        self.trap_state = 5\n",
    "        self.state = self.start_state\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.start_state\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Action: +1 (move right), -1 (move left)\n",
    "        Rewards:\n",
    "          +20 if goal reached\n",
    "          -5 if trap at 5\n",
    "           0 otherwise\n",
    "        \"\"\"\n",
    "        self.state += action\n",
    "        self.state = max(0, min(self.state, self.goal_state))  # keep in [0,10]\n",
    "\n",
    "        if self.state == self.goal_state:\n",
    "            return self.state, 20, True\n",
    "        elif self.state == self.trap_state:\n",
    "            return self.state, -5, False\n",
    "        else:\n",
    "            return self.state, 0, False\n",
    "\n",
    "# Random Agent\n",
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        self.actions = [-1, +1]\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        return random.choice(self.actions)\n",
    "\n",
    "# Run a single episode with detailed step log\n",
    "env = TreasureHuntEnv()\n",
    "agent = RandomAgent()\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "step = 0\n",
    "\n",
    "print(\"Starting episode...\")\n",
    "\n",
    "while not done:\n",
    "    action = agent.choose_action(state)\n",
    "    next_state, reward, done = env.step(action)\n",
    "    print(f\"Step {step}: State={state}, Action={action}, Next State={next_state}, Reward={reward}\")\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    step += 1\n",
    "\n",
    "print(\"Task 2 - Total Reward:\", total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100727e-da06-4f73-b817-d7066e30901e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
